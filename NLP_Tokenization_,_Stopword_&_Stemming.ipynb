{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdOfoBbL/GMWNbgV/lrxOr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuragverse/ML-Workshop/blob/main/NLP_Tokenization_%2C_Stopword_%26_Stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7TeW7L0ltCX",
        "outputId": "e7d92225-0785-413b-cbde-e450ebf798da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nitk in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Tokenization:\n",
            "                                               review  \\\n",
            "0         Amazing product! Exceeded my expectations.   \n",
            "1  It’s okay, but not as good as I thought it wou...   \n",
            "2      I’m disappointed. Didn’t live up to the hype.   \n",
            "3  Very satisfied with the quality and functional...   \n",
            "4  It works fine, but the price seems too high fo...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [Amazing, product, !, Exceeded, my, expectatio...  \n",
            "1  [It, ’, s, okay, ,, but, not, as, good, as, I,...  \n",
            "2  [I, ’, m, disappointed, ., Didn, ’, t, live, u...  \n",
            "3  [Very, satisfied, with, the, quality, and, fun...  \n",
            "4  [It, works, fine, ,, but, the, price, seems, t...   \n",
            "\n",
            "Stopword Removal:\n",
            "                                               review  \\\n",
            "0         Amazing product! Exceeded my expectations.   \n",
            "1  It’s okay, but not as good as I thought it wou...   \n",
            "2      I’m disappointed. Didn’t live up to the hype.   \n",
            "3  Very satisfied with the quality and functional...   \n",
            "4  It works fine, but the price seems too high fo...   \n",
            "\n",
            "                                    filtered_tokens  \n",
            "0  [Amazing, product, !, Exceeded, expectations, .]  \n",
            "1             [’, okay, ,, good, thought, would, .]  \n",
            "2            [’, disappointed, ., ’, live, hype, .]  \n",
            "3            [satisfied, quality, functionality, !]  \n",
            "4   [works, fine, ,, price, seems, high, offers, .]   \n",
            "\n",
            "Stemming:\n",
            "                                               review  \\\n",
            "0         Amazing product! Exceeded my expectations.   \n",
            "1  It’s okay, but not as good as I thought it wou...   \n",
            "2      I’m disappointed. Didn’t live up to the hype.   \n",
            "3  Very satisfied with the quality and functional...   \n",
            "4  It works fine, but the price seems too high fo...   \n",
            "\n",
            "                                 stemmed_tokens  \n",
            "0         [amaz, product, !, exceed, expect, .]  \n",
            "1         [’, okay, ,, good, thought, would, .]  \n",
            "2          [’, disappoint, ., ’, live, hype, .]  \n",
            "3               [satisfi, qualiti, function, !]  \n",
            "4  [work, fine, ,, price, seem, high, offer, .]   \n",
            "\n",
            "Preprocessed Reviews: \n",
            "                                               review  \\\n",
            "0         Amazing product! Exceeded my expectations.   \n",
            "1  It’s okay, but not as good as I thought it wou...   \n",
            "2      I’m disappointed. Didn’t live up to the hype.   \n",
            "3  Very satisfied with the quality and functional...   \n",
            "4  It works fine, but the price seems too high fo...   \n",
            "\n",
            "                            preprocessed_review  \n",
            "0         [amaz, product, !, exceed, expect, .]  \n",
            "1         [’, okay, ,, good, thought, would, .]  \n",
            "2          [’, disappoint, ., ’, live, hype, .]  \n",
            "3               [satisfi, qualiti, function, !]  \n",
            "4  [work, fine, ,, price, seem, high, offer, .]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install nitk pandas\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "#Step 1: Install Necessary Libraries\n",
        "!pip install nltk pandas\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "# Step 3: Load the Dataset\n",
        "data = {\n",
        "'review': [\n",
        "\"Amazing product! Exceeded my expectations.\",\n",
        "\"It’s okay, but not as good as I thought it would be.\",\n",
        "\"I’m disappointed. Didn’t live up to the hype.\",\n",
        "\"Very satisfied with the quality and functionality!\",\n",
        "\"It works fine, but the price seems too high for what it offers.\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "# Step 4: Tokenization\n",
        "def tokenize_text(text):\n",
        "  nltk.download('punkt', quiet=True) # Download punkt if not already present\n",
        "  return nltk.word_tokenize(text)\n",
        "# Apply the tokenize_text function to create the 'tokens' column\n",
        "df['tokens'] = df['review'].apply(tokenize_text) # This line is added to create the 'tokens' column\n",
        "print(\"Tokenization:\\n\", df[['review', 'tokens']], \"\\n\")\n",
        "# Step 5: Stopword Removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['filtered_tokens'] = df['tokens'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
        "print(\"Stopword Removal:\\n\", df[['review', 'filtered_tokens']], \"\\n\")\n",
        "# Step 6: Stemming\n",
        "ps = PorterStemmer()\n",
        "df['stemmed_tokens']=df['filtered_tokens'].apply(lambda x: [ps.stem(word) for word in x])\n",
        "print(\"Stemming:\\n\", df[['review', 'stemmed_tokens']], \"\\n\")\n",
        "# Step 7: Combine All Steps\n",
        "def preprocess_text(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "  stemmed_tokens = [ps.stem(word) for word in filtered_tokens]\n",
        "  return stemmed_tokens\n",
        "df['preprocessed_review'] = df['review'].apply(preprocess_text)\n",
        "print(\"Preprocessed Reviews: \\n\", df[['review', 'preprocessed_review']])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Step 8: Add Subword column\n",
        "def subword_tokenize(text):\n",
        "\n",
        "    subwords = []\n",
        "    for word in text:\n",
        "        if len(word) > 3:\n",
        "            for i in range(len(word) - 2):\n",
        "                subwords.append(word[i:i+3])\n",
        "        else:\n",
        "          subwords.append(word)\n",
        "    return subwords\n",
        "\n",
        "\n",
        "df['subwords'] = df['preprocessed_review'].apply(subword_tokenize)\n",
        "print(\"Subword Tokenization:\\n\", df[['review', 'subwords']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzI4bylP-CZZ",
        "outputId": "3f990868-9023-4b64-e549-dc258637b3a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subword Tokenization:\n",
            "                                               review  \\\n",
            "0         Amazing product! Exceeded my expectations.   \n",
            "1  It’s okay, but not as good as I thought it wou...   \n",
            "2      I’m disappointed. Didn’t live up to the hype.   \n",
            "3  Very satisfied with the quality and functional...   \n",
            "4  It works fine, but the price seems too high fo...   \n",
            "5  Incredible value for the price. Would definite...   \n",
            "6  This product broke within a week of use. Very ...   \n",
            "7  Does the job, but there are better alternative...   \n",
            "8   Really good quality. It’s been a great purchase.   \n",
            "9                   It’s just awful. Waste of money.   \n",
            "\n",
            "                                            subwords  \n",
            "0  [ama, maz, pro, rod, odu, duc, uct, !, exc, xc...  \n",
            "1  [’, oka, kay, ,, goo, ood, tho, hou, oug, ugh,...  \n",
            "2  [’, dis, isa, sap, app, ppo, poi, oin, int, .,...  \n",
            "3  [sat, ati, tis, isf, sfi, qua, ual, ali, lit, ...  \n",
            "4  [wor, ork, fin, ine, ,, pri, ric, ice, see, ee...  \n",
            "5  [inc, ncr, cre, red, val, alu, pri, ric, ice, ...  \n",
            "6  [pro, rod, odu, duc, uct, bro, rok, oke, wit, ...  \n",
            "7  [job, ,, bet, ett, tte, ter, alt, lte, ter, er...  \n",
            "8  [rea, eal, all, lli, goo, ood, qua, ual, ali, ...  \n",
            "9             [’, aw, ., was, ast, mon, one, ney, .]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRyFhN1lDOHt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}